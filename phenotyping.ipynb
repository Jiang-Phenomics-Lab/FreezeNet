{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f02f13d9-c938-4144-aec0-bbf62e8b4952",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import cv2\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from PIL import Image\n",
    "from torch import nn\n",
    "from nets.FreezeNet import FreezeNet\n",
    "import numpy as np\n",
    "\n",
    "from glob import glob\n",
    "import random\n",
    "import matplotlib.pyplot as plt\n",
    "import torch.nn.functional as F\n",
    "from tqdm import tqdm\n",
    "import os\n",
    "import pandas as pd\n",
    "from utils.util import find_ring"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8a1f6410-7158-4783-9d3b-b8683caaf7e6",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def average_non_zero_pixel(gray_image):\n",
    "    non_zero_indices = np.nonzero(gray_image)\n",
    "    non_zero_values = gray_image[non_zero_indices]\n",
    "    average_value = np.mean(non_zero_values)\n",
    "    return average_value\n",
    "\n",
    "def get_green_yello_ratio(new,mask):\n",
    "    hsv=cv2.cvtColor(new,cv2.COLOR_BGR2HSV)\n",
    "    lower_green = np.array([25, 45, 0])\n",
    "    upper_green = np.array([180, 255, 240])\n",
    "    \n",
    "    green_mask = cv2.inRange(hsv, lower_green, upper_green)\n",
    "    new1 = cv2.bitwise_and(new,new,mask=green_mask)\n",
    "    yellow_mask=255*mask-green_mask\n",
    "    yellow_hsv=cv2.bitwise_and(hsv,hsv,mask=yellow_mask)\n",
    "    green_pixels = cv2.countNonZero(green_mask)\n",
    "    total_pixels = cv2.countNonZero(mask)\n",
    "    h,s,v=cv2.split(hsv)\n",
    "    h_value=average_non_zero_pixel(h)\n",
    "    s_value=average_non_zero_pixel(s)\n",
    "    h,s,v=cv2.split(yellow_hsv)\n",
    "    h_y=average_non_zero_pixel(h)\n",
    "    s_y=average_non_zero_pixel(s)\n",
    "    if total_pixels==0:\n",
    "        return 0\n",
    "    ratio_green = green_pixels / total_pixels\n",
    "    return ratio_green,green_pixels,total_pixels-green_pixels,h_value,s_value,h_y,s_y\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e66f8cf0-5c45-4ab4-a0f6-88395539c3ca",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "\n",
    "input_shape=(512,512)\n",
    "model = FreezeNet()\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "model.load_state_dict(torch.load('model/phoneLite.pth', map_location=device))\n",
    "\n",
    "model = nn.DataParallel(model)\n",
    "model = model.to(device)\n",
    "model = model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5419a5fe-a643-4c9e-adf5-e8a43eef4b33",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Progress:: 100%|██████████| 6/6 [00:01<00:00,  3.31it/s<class 'dict'>]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Plot</th>\n",
       "      <th>GreenLeafRation</th>\n",
       "      <th>YellowLeafRation</th>\n",
       "      <th>GreenLeaf</th>\n",
       "      <th>YellowLeafArea</th>\n",
       "      <th>TotalLeafArea</th>\n",
       "      <th>Hue</th>\n",
       "      <th>Sat</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2022C016_20230218_102707</td>\n",
       "      <td>0.118836</td>\n",
       "      <td>0.881164</td>\n",
       "      <td>5297</td>\n",
       "      <td>39277</td>\n",
       "      <td>44574</td>\n",
       "      <td>19.848836</td>\n",
       "      <td>121.652914</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2022C035_20230218_102926</td>\n",
       "      <td>0.064533</td>\n",
       "      <td>0.935467</td>\n",
       "      <td>2474</td>\n",
       "      <td>35863</td>\n",
       "      <td>38337</td>\n",
       "      <td>18.718496</td>\n",
       "      <td>126.385867</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2022C071_20230218_103407</td>\n",
       "      <td>0.493738</td>\n",
       "      <td>0.506262</td>\n",
       "      <td>28699</td>\n",
       "      <td>29427</td>\n",
       "      <td>58126</td>\n",
       "      <td>25.736206</td>\n",
       "      <td>121.858546</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2022C094_20230218_103739</td>\n",
       "      <td>0.112724</td>\n",
       "      <td>0.887276</td>\n",
       "      <td>3744</td>\n",
       "      <td>29470</td>\n",
       "      <td>33214</td>\n",
       "      <td>19.020023</td>\n",
       "      <td>134.975942</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2022C121_20230218_104116</td>\n",
       "      <td>0.106132</td>\n",
       "      <td>0.893868</td>\n",
       "      <td>3683</td>\n",
       "      <td>31019</td>\n",
       "      <td>34702</td>\n",
       "      <td>19.538557</td>\n",
       "      <td>98.618293</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>2022C147_20230218_104450</td>\n",
       "      <td>0.123193</td>\n",
       "      <td>0.876807</td>\n",
       "      <td>3963</td>\n",
       "      <td>28206</td>\n",
       "      <td>32169</td>\n",
       "      <td>19.963008</td>\n",
       "      <td>106.759893</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                       Plot  GreenLeafRation  YellowLeafRation  GreenLeaf  \\\n",
       "0  2022C016_20230218_102707         0.118836          0.881164       5297   \n",
       "1  2022C035_20230218_102926         0.064533          0.935467       2474   \n",
       "2  2022C071_20230218_103407         0.493738          0.506262      28699   \n",
       "3  2022C094_20230218_103739         0.112724          0.887276       3744   \n",
       "4  2022C121_20230218_104116         0.106132          0.893868       3683   \n",
       "5  2022C147_20230218_104450         0.123193          0.876807       3963   \n",
       "\n",
       "   YellowLeafArea  TotalLeafArea        Hue         Sat  \n",
       "0           39277          44574  19.848836  121.652914  \n",
       "1           35863          38337  18.718496  126.385867  \n",
       "2           29427          58126  25.736206  121.858546  \n",
       "3           29470          33214  19.020023  134.975942  \n",
       "4           31019          34702  19.538557   98.618293  \n",
       "5           28206          32169  19.963008  106.759893  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_shape=(512,512)\n",
    "content='Plot,GreenLeafRation,YellowLeafRation,GreenLeaf,YellowLeafArea,TotalLeafArea,Hue,Sat\\n'\n",
    "save_path='phone_phenotypes.csv'\n",
    "with open(save_path,'w',encoding='utf-8') as f:\n",
    "    f.write(content)\n",
    "load=[]   \n",
    "\n",
    "files=sorted(glob('datasets/*.jpg'))\n",
    "with tqdm(total=len(files),desc='Progress:',postfix=dict,mininterval=0.3) as pbar:\n",
    "    for index,file in enumerate(files):\n",
    "        imgname=file.split('/')[-1].split('.')[0]\n",
    "        image = cv2.imread(file)\n",
    "        h,w=image.shape[:2]\n",
    "        if h<w:\n",
    "            image=cv2.rotate(image,cv2.ROTATE_90_CLOCKWISE)\n",
    "            h,w=w,h\n",
    "        ratio=512/w\n",
    "        x1,x2,y1,y2,circles=find_ring(image.copy(),ratio)\n",
    "        new=np.zeros((int(h),int(w),3),dtype=np.uint8)\n",
    "        cv2.circle(new, (round(circles[0][0][0]/ratio), round(circles[0][0][1]/ratio)), round(circles[0][0][2]/ratio), (255, 255, 255), -1)\n",
    "        image=cv2.bitwise_and(image,new)\n",
    "        image=image[y1:y2,x1:x2,:]\n",
    "        image=cv2.resize(image,(input_shape[0],input_shape[0]))\n",
    "        img=torch.from_numpy(image/255).float().to(device)\n",
    "        img=img.unsqueeze(0)\n",
    "        img=img.permute(0,3,1,2)\n",
    "        with torch.no_grad():\n",
    "            output=model(img)\n",
    "        output = output[0].permute(1,2,0).cpu().argmax(axis=-1).numpy().astype(np.uint8)\n",
    "        new = cv2.bitwise_and(image,image,mask=output)\n",
    "        r,g,y,h,s,h_y,s_y=get_green_yello_ratio(new,output)  \n",
    "        with open(save_path,'a',encoding='utf-8') as f:\n",
    "            f.write('{},{},{},{},{},{},{},{}\\n'.format(imgname,r,1-r,g,y,g+y,h,s))\n",
    "        pbar.update(1)\n",
    "pd.read_csv('phone_phenotypes.csv')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "FreezeNet",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.21"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
